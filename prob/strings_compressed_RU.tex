\mysection{Текстовые строки прямо посреди сжатых данных}

\myindex{Ядро Linux}
Вы можете скачать ядра Linux и найти английские слова прямо посреди сжатых данных:

\begin{lstlisting}
% wget https://www.kernel.org/pub/linux/kernel/v4.x/linux-4.10.2.tar.gz

% xxd -g 1 -seek 0x515c550 -l 0x30 linux-4.10.2.tar.gz

0515c550: c5 59 43 cf 41 27 85 54 35 4a 57 90 73 89 b7 6a  .YC.A'.T5JW.s..j
0515c560: 15 af 03 db 20 df 6a 51 f9 56 49 52 55 53 3d da  .... .jQ.VIRUS=.
0515c570: 0e b9 29 24 cc 6a 38 e2 78 66 09 33 72 aa 88 df  ..)$.j8.xf.3r...
\end{lstlisting}

\begin{lstlisting}
% wget https://cdn.kernel.org/pub/linux/kernel/v2.3/linux-2.3.3.tar.bz2

% xxd -g 1 -seek 0xa93086 -l 0x30 linux-2.3.3.tar.bz2

00a93086: 4d 45 54 41 4c cd 44 45 2d 2c 41 41 54 94 8b a1  METAL.DE-,AAT...
00a93096: 5d 2b d8 d0 bd d8 06 91 74 ab 41 a0 0a 8a 94 68  ]+......t.A....h
00a930a6: 66 56 86 81 68 0d 0e 25 6b b6 80 a4 28 1a 00 a4  fV..h..%k...(...
\end{lstlisting}

Один из патчей к ядру Linux в сжатой форме имеет само слово ``Linux'':

\begin{lstlisting}
% wget https://cdn.kernel.org/pub/linux/kernel/v4.x/testing/patch-4.6-rc4.gz

% xxd -g 1 -seek 0x4d03f -l 0x30 patch-4.6-rc4.gz

0004d03f: c7 40 24 bd ae ef ee 03 2c 95 dc 65 eb 31 d3 f1  .@$.....,..e.1..
0004d04f: 4c 69 6e 75 78 f2 f3 70 3c 3a bd 3e bd f8 59 7e  Linux..p<:.>..Y~
0004d05f: cd 76 55 74 2b cb d5 af 7a 35 56 d7 5e 07 5a 67  .vUt+...z5V.^.Zg
\end{lstlisting}

Другие английские слова, которые я нашел в других сжатых исходных кодах ядра Linux:

\begin{lstlisting}
linux-4.6.2.tar.gz: [maybe] at 0x68e78ec
linux-4.10.14.tar.xz: [OCEAN] at 0x6bf0a8
linux-4.7.8.tar.gz: [FUNNY] at 0x29e6e20
linux-4.6.4.tar.gz: [DRINK] at 0x68dc314
linux-2.6.11.8.tar.bz2: [LUCKY] at 0x1ab5be7
linux-3.0.68.tar.gz: [BOOST] at 0x11238c7
linux-3.0.16.tar.bz2: [APPLE] at 0x34c091
linux-3.0.26.tar.xz: [magic] at 0x296f7d9
linux-3.11.8.tar.bz2: [TRUTH] at 0xf635ba
linux-3.10.11.tar.bz2: [logic] at 0x4a7f794
\end{lstlisting}

\myindex{Апофения}
\myindex{Парейдолия}
\myindex{Луркмор}
В Луркморе есть неплохая иллюстрация апофении и парейдолии (способность человеческого разума видеть лица в облаках, итд).
Как они пишут в статье об электронном голосовом феномене\footnote{\url{http://archive.is/gYnFL}},
вы можете открыть любой достаточно большой файл в шестнадцатеричном редакторе и найти одно хорошо известное русское матерное слово из трех букв, и вы найдете их много: но это ничего не значит, просто совпадение.

И мне было интересно посчитать, насколько большой должен быть сжатый файл, чтобы в нем можно было найти все возможные слова из трех букв, четырех, итд?
В моих наивных выкладках я дошел до этого: вероятность встретить первый байт посреди потока со сжатыми данными с максимальной энтропией это 
$\frac{1}{256}$, вероятность второго это тоже $\frac{1}{256}$,
и вероятность определенной пары байт это $\frac{1}{256 \cdot 256} = \frac{1}{256^2}$.
Вероятность определенной тройки это $\frac{1}{256^3}$.
Если у файла максимальная энтропия (что почти недостижимо, но \dots), и мы живем в идеальном мире, вам нужен файл размером всего $256^3=16777216$, а это 16-17MB.
\myindex{rafind2}
Можете проверите: возьмите любой сжатый файл, и используя \IT{rafind2} найдите любое слово из трех букв (не только это русское матерное).

Мне понадобилось $\approx$ 8-9 GB скачанных фильмов и сериалов чтобы найти там слово ``beer'' (в том же регистре).
Вероятно, эти фильмы не так хорошо сжаты?
Это также справедливо и для хорошо известного четырехбуквенного английского матерного слова.

Мой подход наивный, так что я погуглил математически обоснованный, и нашел этот вопрос:
``Time until a consecutive sequence of ones in a random bit sequence''
\footnote{\url{http://math.stackexchange.com/questions/27989/time-until-a-consecutive-sequence-of-ones-in-a-random-bit-sequence/27991#27991}}.
Ответ это: $(p^{−n}−1)/(1−p)$, где $p$ это вероятность каждого события и $n$ это количество последовательных событий.
Используйте $\frac{1}{256}$ и $3$ и получите почти то же что получил и я в своих наивных выкладках.

Так что любое трехбуквенное слово можно найти в сжатом файле (с идеальной энтропией) длиной $256^3 = \approx 17MB$, любое четырехбуквенное слово --- $256^4 = 4.7GB$ (размер DVD).
Любое пятибуквенное слово --- $256^5 = \approx 1TB$.

Ради фрагмента текста, который вы сейчас читаете, я скачал весь сайт \href{https://www.kernel.org/}{kernel.org} (надеюсь, сисадмины простят меня),
и он содержит $\approx$ 430GB сжатых исходных кодов разных версий ядер Linux.
Там есть достаточно сжатых данных, чтобы содержать все эти слова, хотя, я немного сжульничал: я искал строки в обоих регистрах, таким образом, необходимый набор сжатых данных стал в половину меньше.

На самом деле, это очень интересная тема для размышлений: 1TB сжатых данных с максимальной энтропией содержит все возможные цепочки из пяти байт,
но данные кодируются не в самих цепочках, а в их последовательности (вне зависимости от алгоритма сжатия, итд).

Теперь информация для игроманов: нужно бросить кость $\approx 42$ раза, чтобы получить один раз пару из шести, но никто вам не скажет, когда именно это случится.
\myindex{Розенкранц и Гильденстерн мертвы}
Я не помню, сколько раз подбрасывалась монета в фильме ``Розенкранц и Гильденстерн мертвы'', но её нужно подбросить $\approx 2048$ раз, и в какой-то момент, вы увидите 10 решек подряд, а в другой момент,
10 орлов поряд.
Опять же, вам никто не скажет, когда именно это случится.

Сжатые данные также можно считать потоком случайной информации, так что мы можем использовать ту же математику, что и для теории вероятности, итд.

Если вам сгодятся строки с символами в смешанном регистре, как ``bEeR'', вероятности и объемы сжатых данных намного меньше:
$128^3=2MB$ для всех слов из трех букв в смешанном регистре,
$128^4=268MB$ для всех слов из 4-х буквы,
$128^5=34GB$ для всех слов из 5-и букв, итд.

\myindex{Хорхе Луис Борхес}
Мораль сей истории: когда вы ищете что-то и находите это прямо посреди большого сжатого блоба, это может быть просто совпадение.
В философском смысле, это selection/confirmation bias (систематическая ошибка отбора/склонность к подтверждению своей точки зрения):
вы находите то, что ишете в ``Вавилонской библиотеке''\footnote{Рассказ Хорхе Луиса Борхеса}.

